{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "Copy of updated2_A3cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ii6Z49SknI00"
      },
      "source": [
        "Build CNN:\n",
        "- import libraries\n",
        "- Load and normalize data\n",
        "- OHEC data\n",
        "- Split data into training and test\n",
        "- Build CNN class with layers\n",
        "- Evaluate model\n",
        "- Tune hyper params\n",
        "- Improve model and see what can be done better\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ZgdDEZgVnI1H"
      },
      "source": [
        "The basic steps to build an image classification model using a neural network are:\n",
        "\n",
        "- Flatten the input image dimensions to 1D (width pixels x height pixels)\n",
        "- Normalize the image pixel values (divide by 255)\n",
        "- One-Hot Encode the categorical column\n",
        "- Build a model architecture (Sequential) with Dense layers\n",
        "- Train the model and make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "oQ25fdMRnI1L"
      },
      "source": [
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "J6gy1OCpnI1N"
      },
      "source": [
        "class ConfigureDataset(Dataset):\n",
        "    def __init__(self, X_Train, Y_Train, transform=None):\n",
        "        self.X_Train = X_Train\n",
        "        self.Y_Train = Y_Train\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_Train)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X_Train[idx]\n",
        "        y = self.Y_Train[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "vOl4uawTnI1N"
      },
      "source": [
        "# converts labels from an array of 36 to a value between 0 nd 259\n",
        "def convert_label(label):\n",
        "    numl = label[:10]\n",
        "    letter = label[10:]\n",
        "    return 26 * np.where(numl == 1)[0][0] + np.where(letter == 1)[0][0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4bUlPDHnI1P",
        "outputId": "26955515-f6e6-4082-90ea-cd33f40212e9"
      },
      "source": [
        "file = open('.../data/images_l.pkl', 'rb')\n",
        "X_data = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "file = open('.../data/labels_l.pkl', 'rb')\n",
        "Y_data = pkl.load(file)\n",
        "file.close()\n",
        "\n",
        "Y_data_2 = []\n",
        "print(Y_data[:10])\n",
        "for idx in range(len(Y_data)):\n",
        "    Y_data_2.append(convert_label(Y_data[idx]))\n",
        "print(Y_data_2[:10])\n",
        "\n",
        "X_train = X_data[:25000]\n",
        "Y_train = Y_data_2[:25000]\n",
        "\n",
        "X_test = X_data[25000:]\n",
        "Y_test = Y_data_2[25000:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[238, 146, 216, 131, 124, 142, 162, 228, 120, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7VHDUWgnI1Q",
        "outputId": "5f99e35b-a74a-4bd0-8a0a-4b7769af9ad8"
      },
      "source": [
        "print(type(X_train[0][0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.float64'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "c_19tcDhnI1R"
      },
      "source": [
        "train_set = ConfigureDataset(X_train, Y_train, transform=transforms.Compose([transforms.ToTensor(),transforms.RandomHorizontalFlip(), transforms.Normalize(12.2904, 48.2189)]))\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mCMw7lzZnI1R"
      },
      "source": [
        "test_set = ConfigureDataset(X_test, Y_test, transform=transforms.Compose([transforms.ToTensor(), transforms.RandomHorizontalFlip(), transforms.Normalize(12.2904, 48.2189)]))\n",
        "test_loader = DataLoader(test_set, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6eIKjjeknI1T"
      },
      "source": [
        "def get_mean_and_std(dataloader):\n",
        "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "    for data, _ in dataloader:\n",
        "        # Mean over batch, height and width, but not over the channels\n",
        "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
        "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
        "        num_batches += 1\n",
        "\n",
        "    mean = channels_sum / num_batches\n",
        "\n",
        "    # std = sqrt(E[X^2] - (E[X])^2)\n",
        "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
        "\n",
        "    return mean, std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv2Gg2UxnI1T",
        "outputId": "8591a05b-47dd-42a0-9561-2d5e1b41a674"
      },
      "source": [
        "print(next(iter(train_loader))[0][0].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-0.0381, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKnyOk5OnI1U",
        "outputId": "b5909781-619b-42eb-92ba-fb39f9179428"
      },
      "source": [
        "print(get_mean_and_std(train_loader))\n",
        "print(get_mean_and_std(test_loader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([1.4850e-05], dtype=torch.float64), tensor([1.0000], dtype=torch.float64))\n",
            "(tensor([0.0005], dtype=torch.float64), tensor([1.0017], dtype=torch.float64))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "-KUnKGcAnI1V",
        "outputId": "6779e821-0236-4180-ff34-510d206f25db"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "# print(images)\n",
        "# print(labels)\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images[:4]))\n",
        "# print labels\n",
        "print(' '.join('%5s' % convert_label(labels[j]) for j in range(8)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-f90c9ab884bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# print labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%5s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconvert_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-71-f90c9ab884bd>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# print labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%5s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconvert_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-66-fcd19d0dc1be>\u001b[0m in \u001b[0;36mconvert_label\u001b[0;34m(label)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# converts labels from an array of 36 to a value between 0 nd 259\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mnuml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mletter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m26\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuml\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: slice() cannot be applied to a 0-dim tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_lU_n4oOnI1W"
      },
      "source": [
        "# Define a convolutional neural network\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv_layer_1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 128, 5),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2)\n",
        "        )\n",
        "\n",
        "        self.conv_layer_2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2)\n",
        "        )\n",
        "\n",
        "        self.conv_layer_3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, 3),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2,2)\n",
        "        )\n",
        "\n",
        "        self.full_layer_1 = nn.Sequential(\n",
        "            nn.Linear(256 * 5 * 5, 1024),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.output_layer = nn.Sequential(\n",
        "            nn.Linear(1024, 260),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layer_1(x)\n",
        "        x = self.conv_layer_2(x)\n",
        "        x = self.conv_layer_3(x)\n",
        "        x = x.view(-1, 256 * 5 * 5)\n",
        "        x = self.full_layer_1(x)\n",
        "        x = self.output_layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "SU8UGjctnI1W"
      },
      "source": [
        "# Define a loss function and optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=3e-4, weight_decay=1e-5)#lr=0.01,momentum=0.9,lr=3e-4\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uAkbTAMUnI1X"
      },
      "source": [
        "# test one set of images\n",
        "# images and lables from image print cell\n",
        "# zero the parameter gradients\n",
        "optimizer.zero_grad()\n",
        "\n",
        "images, labels = images.cuda(), labels.cuda()#when using gpu uncomment\n",
        "\n",
        "# forward + backward + optimize\n",
        "outputs = net(images.float())\n",
        "loss = criterion(outputs, labels)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "\n",
        "_, predicted = torch.max(outputs.data, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F66JWE6nI1b",
        "outputId": "d24ec1fb-bfad-4b47-aa14-550b49081db5"
      },
      "source": [
        "print(loss)\n",
        "print(labels)\n",
        "print(predicted)\n",
        "print((predicted == labels).sum().item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5.5793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor([127, 217, 211,  72,  14,  39, 200,  64,  46, 233,   2,  82, 152, 207,\n",
            "         13, 128,   5, 126, 215,  81,  83,   6,  77,  92,  89, 197, 238, 105,\n",
            "         83,  93, 255,  50, 204, 118,  48,  11,  86, 233, 124, 184, 197, 204,\n",
            "        253, 135, 150,   7,  47, 146, 204, 107, 166, 167, 213, 221, 174, 198,\n",
            "         52, 168, 226,  49, 220,   7, 216, 206], device='cuda:0')\n",
            "tensor([106, 194, 206,  48,  48,  48,  48, 194, 173, 179,  51, 173,  48, 156,\n",
            "         49,  48,  48, 173,  55,  48, 173, 173,  48,  48, 173,  48, 173, 173,\n",
            "        173,  51,  48,  48, 173,  48, 194,  48, 194,  48, 173, 173,  48, 246,\n",
            "        231,  48,  48,  49, 173, 173, 173,  48, 173, 173,  15, 173, 173, 194,\n",
            "        156,  48, 248, 173, 179, 173, 173,  11], device='cuda:0')\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NIg3Im4nI1c",
        "outputId": "7a422c9b-7fda-4906-e195-c2dcace2fdc3"
      },
      "source": [
        "# Train the network\n",
        "\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "    net = net.float()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()#when using gpu uncomment\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs.float())\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 50 == 49:    # print every 50 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 50))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,    50] loss: 5.553\n",
            "[1,   100] loss: 4.949\n",
            "[1,   150] loss: 4.429\n",
            "[1,   200] loss: 4.134\n",
            "[1,   250] loss: 4.015\n",
            "[1,   300] loss: 3.920\n",
            "[1,   350] loss: 3.846\n",
            "[2,    50] loss: 3.702\n",
            "[2,   100] loss: 3.670\n",
            "[2,   150] loss: 3.552\n",
            "[2,   200] loss: 3.528\n",
            "[2,   250] loss: 3.451\n",
            "[2,   300] loss: 3.357\n",
            "[2,   350] loss: 3.279\n",
            "[3,    50] loss: 3.170\n",
            "[3,   100] loss: 3.112\n",
            "[3,   150] loss: 3.054\n",
            "[3,   200] loss: 2.978\n",
            "[3,   250] loss: 2.928\n",
            "[3,   300] loss: 2.892\n",
            "[3,   350] loss: 2.815\n",
            "[4,    50] loss: 2.605\n",
            "[4,   100] loss: 2.578\n",
            "[4,   150] loss: 2.476\n",
            "[4,   200] loss: 2.447\n",
            "[4,   250] loss: 2.380\n",
            "[4,   300] loss: 2.328\n",
            "[4,   350] loss: 2.336\n",
            "[5,    50] loss: 2.142\n",
            "[5,   100] loss: 2.062\n",
            "[5,   150] loss: 2.039\n",
            "[5,   200] loss: 1.997\n",
            "[5,   250] loss: 1.982\n",
            "[5,   300] loss: 1.950\n",
            "[5,   350] loss: 1.934\n",
            "[6,    50] loss: 1.740\n",
            "[6,   100] loss: 1.683\n",
            "[6,   150] loss: 1.705\n",
            "[6,   200] loss: 1.621\n",
            "[6,   250] loss: 1.667\n",
            "[6,   300] loss: 1.644\n",
            "[6,   350] loss: 1.579\n",
            "[7,    50] loss: 1.468\n",
            "[7,   100] loss: 1.401\n",
            "[7,   150] loss: 1.448\n",
            "[7,   200] loss: 1.370\n",
            "[7,   250] loss: 1.414\n",
            "[7,   300] loss: 1.381\n",
            "[7,   350] loss: 1.327\n",
            "[8,    50] loss: 1.228\n",
            "[8,   100] loss: 1.221\n",
            "[8,   150] loss: 1.224\n",
            "[8,   200] loss: 1.194\n",
            "[8,   250] loss: 1.173\n",
            "[8,   300] loss: 1.183\n",
            "[8,   350] loss: 1.259\n",
            "[9,    50] loss: 1.050\n",
            "[9,   100] loss: 1.034\n",
            "[9,   150] loss: 1.046\n",
            "[9,   200] loss: 1.047\n",
            "[9,   250] loss: 1.103\n",
            "[9,   300] loss: 1.061\n",
            "[9,   350] loss: 1.033\n",
            "[10,    50] loss: 0.908\n",
            "[10,   100] loss: 0.966\n",
            "[10,   150] loss: 0.950\n",
            "[10,   200] loss: 0.972\n",
            "[10,   250] loss: 0.897\n",
            "[10,   300] loss: 0.959\n",
            "[10,   350] loss: 0.909\n",
            "[11,    50] loss: 0.817\n",
            "[11,   100] loss: 0.832\n",
            "[11,   150] loss: 0.827\n",
            "[11,   200] loss: 0.815\n",
            "[11,   250] loss: 0.844\n",
            "[11,   300] loss: 0.819\n",
            "[11,   350] loss: 0.850\n",
            "[12,    50] loss: 0.741\n",
            "[12,   100] loss: 0.705\n",
            "[12,   150] loss: 0.705\n",
            "[12,   200] loss: 0.759\n",
            "[12,   250] loss: 0.772\n",
            "[12,   300] loss: 0.766\n",
            "[12,   350] loss: 0.722\n",
            "[13,    50] loss: 0.618\n",
            "[13,   100] loss: 0.637\n",
            "[13,   150] loss: 0.638\n",
            "[13,   200] loss: 0.670\n",
            "[13,   250] loss: 0.672\n",
            "[13,   300] loss: 0.684\n",
            "[13,   350] loss: 0.697\n",
            "[14,    50] loss: 0.602\n",
            "[14,   100] loss: 0.551\n",
            "[14,   150] loss: 0.578\n",
            "[14,   200] loss: 0.613\n",
            "[14,   250] loss: 0.639\n",
            "[14,   300] loss: 0.599\n",
            "[14,   350] loss: 0.617\n",
            "[15,    50] loss: 0.504\n",
            "[15,   100] loss: 0.464\n",
            "[15,   150] loss: 0.523\n",
            "[15,   200] loss: 0.506\n",
            "[15,   250] loss: 0.519\n",
            "[15,   300] loss: 0.553\n",
            "[15,   350] loss: 0.567\n",
            "[16,    50] loss: 0.459\n",
            "[16,   100] loss: 0.469\n",
            "[16,   150] loss: 0.515\n",
            "[16,   200] loss: 0.467\n",
            "[16,   250] loss: 0.441\n",
            "[16,   300] loss: 0.492\n",
            "[16,   350] loss: 0.493\n",
            "[17,    50] loss: 0.395\n",
            "[17,   100] loss: 0.391\n",
            "[17,   150] loss: 0.401\n",
            "[17,   200] loss: 0.443\n",
            "[17,   250] loss: 0.442\n",
            "[17,   300] loss: 0.446\n",
            "[17,   350] loss: 0.459\n",
            "[18,    50] loss: 0.368\n",
            "[18,   100] loss: 0.342\n",
            "[18,   150] loss: 0.384\n",
            "[18,   200] loss: 0.378\n",
            "[18,   250] loss: 0.380\n",
            "[18,   300] loss: 0.379\n",
            "[18,   350] loss: 0.385\n",
            "[19,    50] loss: 0.345\n",
            "[19,   100] loss: 0.337\n",
            "[19,   150] loss: 0.304\n",
            "[19,   200] loss: 0.363\n",
            "[19,   250] loss: 0.353\n",
            "[19,   300] loss: 0.345\n",
            "[19,   350] loss: 0.356\n",
            "[20,    50] loss: 0.274\n",
            "[20,   100] loss: 0.269\n",
            "[20,   150] loss: 0.299\n",
            "[20,   200] loss: 0.314\n",
            "[20,   250] loss: 0.324\n",
            "[20,   300] loss: 0.313\n",
            "[20,   350] loss: 0.365\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-DSIqGVrnI1d"
      },
      "source": [
        "print(list(net.parameters()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jTrTkOlAnI1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09cfb4f8-983d-4c9c-92ff-afab3535a6ac"
      },
      "source": [
        "testiter = iter(test_loader)\n",
        "images, labels = next(testiter)\n",
        "\n",
        "images, labels = images.cuda(), labels.cuda()#uncomment when using gpu\n",
        "\n",
        "outputs = net(images.float())\n",
        "print(outputs.data)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "print(predicted)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-29.0355, -56.3075, -14.9616,  ..., -33.2334, -15.2489, -27.8930],\n",
            "        [-19.8796, -44.1998, -22.8922,  ..., -21.3754,  -8.7808, -44.5773],\n",
            "        [-18.5265, -40.8488, -46.1105,  ..., -12.4878, -20.9681, -23.5038],\n",
            "        ...,\n",
            "        [-19.9764, -21.9750, -36.7555,  ..., -30.3611, -32.4980, -16.7026],\n",
            "        [-22.5621, -33.8767, -22.5670,  ..., -25.4388, -19.6531, -37.1469],\n",
            "        [-40.3006, -20.4145, -42.1556,  ..., -41.4918, -49.7571, -32.4384]],\n",
            "       device='cuda:0')\n",
            "tensor([217, 180, 238, 190,  55,  67,  69, 204,  17, 189, 233, 250, 228,  17,\n",
            "         76,  34, 164, 168,   5,  16, 122, 180,  76, 213, 113, 114,  17, 184,\n",
            "        212, 113, 102, 212,  74, 240, 153, 238,  87,  45, 221, 246,  32,  77,\n",
            "         78, 212,  12, 154,  67, 239, 170, 151, 133, 192, 160,   4,  60, 241,\n",
            "         36,  82, 117, 184, 125, 172, 151, 167], device='cuda:0')\n",
            "tensor([217, 228, 108, 190,  55, 233,  69, 204,  17, 189, 233, 250, 228,  17,\n",
            "         46,  34, 164, 168,   5, 235, 122, 180, 122, 213, 113, 109,  17, 184,\n",
            "        212, 117, 102, 212,  74, 240, 153, 238, 138,  49, 221, 246, 158,  77,\n",
            "         78, 212,  12, 154, 246, 239, 209, 151, 133, 192, 160,  55,  60, 241,\n",
            "         36, 155, 117, 184,  74, 212, 151,  72], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "P-eJCTxYnI1e"
      },
      "source": [
        "# Let's see how the network performs on the whole test dataset\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "\n",
        "        images, labels = images.cuda(), labels.cuda() #uncomment when using gpu\n",
        "\n",
        "        outputs = net(images.float())\n",
        "        # _, predicted = torch.topk(outputs, 2)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += len(labels)\n",
        "        correct += (predicted == labels).sum().item()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "R3XFRpCbnI1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7444ff5a-eaf3-4a97-85a9-1c4299324d1b"
      },
      "source": [
        "print(outputs.shape)\n",
        "print(labels.shape)\n",
        "print(total)\n",
        "print(correct)\n",
        "\n",
        "print(torch.max(outputs.data, 1))\n",
        "print(labels)\n",
        "\n",
        "print('Accuracy of the network on the 5000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 260])\n",
            "torch.Size([8])\n",
            "5000\n",
            "3602\n",
            "torch.return_types.max(\n",
            "values=tensor([  4.2869, -10.1858,  -0.7809,  -3.6001,   4.8804,  -4.0561,  -6.6670,\n",
            "         -0.4196], device='cuda:0'),\n",
            "indices=tensor([174, 100,  49, 136,  49, 257, 107, 122], device='cuda:0'))\n",
            "tensor([174, 100,  49, 135,  49, 257, 107, 122], device='cuda:0')\n",
            "Accuracy of the network on the 5000 test images: 72 %\n"
          ]
        }
      ]
    }
  ]
}