{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Build CNN:\n",
    "- import libraries\n",
    "- Load and normalize data\n",
    "- OHEC data\n",
    "- Split data into training and test\n",
    "- Build CNN class with layers\n",
    "- Evaluate model\n",
    "- Tune hyper params\n",
    "- Improve model and see what can be done better\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The basic steps to build an image classification model using a neural network are:\n",
    "\n",
    "- Flatten the input image dimensions to 1D (width pixels x height pixels)\n",
    "- Normalize the image pixel values (divide by 255)\n",
    "- One-Hot Encode the categorical column\n",
    "- Build a model architecture (Sequential) with Dense layers\n",
    "- Train the model and make predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ConfigureDataset(Dataset):\n",
    "    def __init__(self, X_Train, Y_Train, transform=None):\n",
    "        self.X_Train = X_Train\n",
    "        self.Y_Train = Y_Train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_Train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X_Train[idx]\n",
    "        y = self.Y_Train[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# converts labels from an array of 36 to a value between 0 nd 259\n",
    "def convert_label(label):\n",
    "    numl = label[:10]\n",
    "    letter = label[10:]\n",
    "    return 26 * np.where(numl == 1)[0][0] + np.where(letter == 1)[0][0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file = open('../data/images_l.pkl', 'rb')\n",
    "X_data = pkl.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('../data/labels_l.pkl', 'rb')\n",
    "Y_data = pkl.load(file)\n",
    "file.close()\n",
    "\n",
    "Y_data_2 = []\n",
    "print(Y_data[:10])\n",
    "for idx in range(len(Y_data)):\n",
    "    Y_data_2.append(convert_label(Y_data[idx]))\n",
    "print(Y_data_2[:10])\n",
    "\n",
    "X_train = X_data[:25000]\n",
    "Y_train = Y_data_2[:25000]\n",
    "\n",
    "X_test = X_data[25000:]\n",
    "Y_test = Y_data_2[25000:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(type(X_train[0][0][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set = ConfigureDataset(X_train, Y_train, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize(12.2904, 48.2189)]))\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "test_set = ConfigureDataset(X_test, Y_test, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize(12.2904, 48.2189)]))\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "\n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(next(iter(train_loader))[0][0].mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(get_mean_and_std(train_loader))\n",
    "print(get_mean_and_std(test_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "# print(images)\n",
    "# print(labels)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print labels\n",
    "print(' '.join('%5s' % convert_label(labels[j]) for j in range(8)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "# Define a convolutional neural network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, 5),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "\n",
    "        self.conv_layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "\n",
    "        self.conv_layer_3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 3),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "\n",
    "        self.full_layer_1 = nn.Sequential(\n",
    "            nn.Linear(256 * 5 * 5, 1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(1024, 260),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.conv_layer_2(x)\n",
    "        x = self.conv_layer_3(x)\n",
    "        x = x.view(-1, 256 * 5 * 5)\n",
    "        x = self.full_layer_1(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "# Define a loss function and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# test one set of images\n",
    "# images and lables from image print cell\n",
    "# zero the parameter gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# forward + backward + optimize\n",
    "outputs = net(images.float())\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "_, predicted = torch.max(outputs.data, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(loss)\n",
    "print(labels)\n",
    "print(predicted)\n",
    "print((predicted == labels).sum().item())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 5.569\n",
      "[1,   100] loss: 5.489\n",
      "[1,   150] loss: 5.336\n",
      "[1,   200] loss: 5.132\n",
      "[1,   250] loss: 4.952\n",
      "[1,   300] loss: 4.834\n",
      "[1,   350] loss: 4.694\n",
      "[2,    50] loss: 4.381\n",
      "[2,   100] loss: 4.268\n",
      "[2,   150] loss: 4.193\n",
      "[2,   200] loss: 4.109\n",
      "[2,   250] loss: 4.071\n",
      "[2,   300] loss: 4.032\n",
      "[2,   350] loss: 3.983\n",
      "[3,    50] loss: 3.810\n",
      "[3,   100] loss: 3.778\n",
      "[3,   150] loss: 3.750\n",
      "[3,   200] loss: 3.717\n",
      "[3,   250] loss: 3.659\n",
      "[3,   300] loss: 3.626\n",
      "[3,   350] loss: 3.576\n",
      "[4,    50] loss: 3.418\n",
      "[4,   100] loss: 3.358\n",
      "[4,   150] loss: 3.345\n",
      "[4,   200] loss: 3.375\n",
      "[4,   250] loss: 3.337\n",
      "[4,   300] loss: 3.291\n",
      "[4,   350] loss: 3.261\n",
      "[5,    50] loss: 3.123\n",
      "[5,   100] loss: 3.086\n",
      "[5,   150] loss: 3.069\n",
      "[5,   200] loss: 3.068\n",
      "[5,   250] loss: 3.043\n",
      "[5,   300] loss: 2.982\n",
      "[5,   350] loss: 2.985\n",
      "[6,    50] loss: 2.818\n",
      "[6,   100] loss: 2.793\n",
      "[6,   150] loss: 2.746\n",
      "[6,   200] loss: 2.731\n",
      "[6,   250] loss: 2.716\n",
      "[6,   300] loss: 2.691\n",
      "[6,   350] loss: 2.641\n",
      "[7,    50] loss: 2.451\n",
      "[7,   100] loss: 2.442\n",
      "[7,   150] loss: 2.456\n",
      "[7,   200] loss: 2.435\n",
      "[7,   250] loss: 2.392\n",
      "[7,   300] loss: 2.369\n",
      "[7,   350] loss: 2.345\n",
      "[8,    50] loss: 2.124\n",
      "[8,   100] loss: 2.166\n",
      "[8,   150] loss: 2.118\n",
      "[8,   200] loss: 2.076\n",
      "[8,   250] loss: 2.096\n",
      "[8,   300] loss: 2.064\n",
      "[8,   350] loss: 2.052\n",
      "[9,    50] loss: 1.828\n",
      "[9,   100] loss: 1.795\n",
      "[9,   150] loss: 1.804\n",
      "[9,   200] loss: 1.808\n",
      "[9,   250] loss: 1.773\n",
      "[9,   300] loss: 1.745\n",
      "[9,   350] loss: 1.760\n",
      "[10,    50] loss: 1.503\n",
      "[10,   100] loss: 1.443\n",
      "[10,   150] loss: 1.428\n",
      "[10,   200] loss: 1.516\n",
      "[10,   250] loss: 1.413\n",
      "[10,   300] loss: 1.449\n",
      "[10,   350] loss: 1.411\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    net = net.float()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 50 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 50))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(list(net.parameters()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testiter = iter(test_loader)\n",
    "images, labels = next(testiter)\n",
    "outputs = net(images.float())\n",
    "print(outputs.data)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print(predicted)\n",
    "print(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [],
   "source": [
    "# Let's see how the network performs on the whole test dataset\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images.float())\n",
    "        # _, predicted = torch.topk(outputs, 2)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total += len(labels)\n",
    "        correct += (predicted == labels).sum().item()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 260])\n",
      "torch.Size([8])\n",
      "5000\n",
      "1967\n",
      "torch.return_types.max(\n",
      "values=tensor([11.2178, 14.0849, 14.6959, 13.0774,  9.6836, 13.3521, 15.1238, 14.9103]),\n",
      "indices=tensor([159, 164, 181,  80, 244,  14,  97, 127]))\n",
      "tensor([167, 138, 174,  80, 109,  14,  97,  33])\n",
      "Accuracy of the network on the 5000 test images: 39 %\n"
     ]
    }
   ],
   "source": [
    "print(outputs.shape)\n",
    "print(labels.shape)\n",
    "print(total)\n",
    "print(correct)\n",
    "\n",
    "print(torch.max(outputs.data, 1))\n",
    "print(labels)\n",
    "\n",
    "print('Accuracy of the network on the 5000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}